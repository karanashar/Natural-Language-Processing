{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('clothing_shoes_jewelry.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "regex=re.compile(('^reviewText'))\n",
    "file2write=open(\"filename1.txt\",'w')\n",
    "for i in lines:\n",
    "    if(re.match(regex,i)):\n",
    "        \n",
    "        file2write.write(i[11:])\n",
    "\n",
    "file2write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import os\n",
    "mycorpus = PlaintextCorpusReader('.', '.*\\.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorpus = mycorpus.raw('filename1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=nltk.word_tokenize(mycorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token1=[w for w in token if w.isalpha()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2=[w for w in token1 if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsUpper=[]\n",
    "for i in stopwords:\n",
    "    stopwordsUpper.append(i.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token3=[w for w in token2 if w not in stopwordsUpper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('like', 87738)\n",
      "('size', 83282)\n",
      "('wear', 78845)\n",
      "('fit', 77125)\n",
      "('great', 65445)\n",
      "('would', 63288)\n",
      "('comfortable', 55353)\n",
      "('well', 54539)\n",
      "('good', 54105)\n",
      "('one', 52962)\n",
      "('shoes', 49574)\n",
      "('love', 47390)\n",
      "('really', 43427)\n",
      "('little', 42321)\n",
      "('look', 41726)\n",
      "('nice', 40757)\n",
      "('bought', 38196)\n",
      "('get', 37906)\n",
      "('price', 33953)\n",
      "('pair', 33365)\n",
      "('color', 32649)\n",
      "('time', 32330)\n",
      "('small', 31923)\n",
      "('quality', 31859)\n",
      "('ordered', 31306)\n",
      "('shoe', 30752)\n",
      "('much', 28955)\n",
      "('perfect', 28385)\n",
      "('buy', 27843)\n",
      "('made', 27290)\n",
      "('got', 26588)\n",
      "('watch', 26088)\n",
      "('bit', 25803)\n",
      "('long', 25005)\n",
      "('feet', 24897)\n",
      "('looks', 24752)\n",
      "('also', 24245)\n",
      "('even', 23492)\n",
      "('fits', 22847)\n",
      "('recommend', 22556)\n",
      "('back', 22520)\n",
      "('work', 22236)\n",
      "('still', 22029)\n",
      "('wearing', 21938)\n",
      "('big', 21937)\n",
      "('looking', 21017)\n",
      "('could', 20797)\n",
      "('pretty', 20450)\n",
      "('right', 20337)\n",
      "('material', 20204)\n"
     ]
    }
   ],
   "source": [
    "freq1=FreqDist(token3)\n",
    "topkeys=freq1.most_common(50)\n",
    "for pair in topkeys:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewbigrams = list(nltk.bigrams(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'great'),\n",
       " ('great', 'tutu'),\n",
       " ('tutu', 'and'),\n",
       " ('and', 'at'),\n",
       " ('at', 'a'),\n",
       " ('a', 'really'),\n",
       " ('really', 'great'),\n",
       " ('great', 'price'),\n",
       " ('price', '.'),\n",
       " ('.', 'It'),\n",
       " ('It', 'does'),\n",
       " ('does', \"n't\"),\n",
       " (\"n't\", 'look'),\n",
       " ('look', 'cheap'),\n",
       " ('cheap', 'at'),\n",
       " ('at', 'all'),\n",
       " ('all', '.'),\n",
       " ('.', 'I')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewbigrams[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alpha(w):\n",
    "    if(w.isalpha()):\n",
    "        return False\n",
    "    else:return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('well', 'made'), 0.0004223229196771571)\n",
      "(('would', 'recommend'), 0.00027974470381769305)\n",
      "(('good', 'quality'), 0.00025981497510449056)\n",
      "(('really', 'like'), 0.00025138516818141277)\n",
      "(('fit', 'perfectly'), 0.00022286952500951996)\n",
      "(('look', 'like'), 0.00021938312338083964)\n",
      "(('fit', 'well'), 0.0002168854028110388)\n",
      "(('highly', 'recommend'), 0.00020783116574551078)\n",
      "(('another', 'pair'), 0.0001980484268471242)\n",
      "(('look', 'great'), 0.00018743311442547068)\n",
      "(('looks', 'great'), 0.0001821254582146439)\n",
      "(('year', 'old'), 0.00018129288469137696)\n",
      "(('feel', 'like'), 0.00017962773764484307)\n",
      "(('looks', 'like'), 0.00016937667613961882)\n",
      "(('usually', 'wear'), 0.0001590735787891904)\n",
      "(('fit', 'great'), 0.00015537903377969335)\n",
      "(('normally', 'wear'), 0.00014648090424977789)\n",
      "(('long', 'time'), 0.00014356689691834358)\n",
      "(('light', 'weight'), 0.0001402366028252758)\n",
      "(('one', 'size'), 0.0001382592407075168)\n",
      "(('every', 'day'), 0.00013789498979108753)\n",
      "(('even', 'though'), 0.00013659409366098294)\n",
      "(('arch', 'support'), 0.00013617780689934947)\n",
      "(('size', 'larger'), 0.00013362805048434444)\n",
      "(('look', 'good'), 0.00013060997146250176)\n",
      "(('little', 'bit'), 0.00012837243011872186)\n",
      "(('half', 'size'), 0.00012472992095442897)\n",
      "(('great', 'price'), 0.00012348106066952856)\n",
      "(('first', 'time'), 0.00012030687411207334)\n",
      "(('fits', 'well'), 0.00011942226474360221)\n",
      "(('would', 'buy'), 0.00011879783460115202)\n",
      "(('much', 'better'), 0.00011375035761634616)\n",
      "(('fits', 'perfectly'), 0.00011338610669991688)\n",
      "(('really', 'nice'), 0.00011224131810542483)\n",
      "(('different', 'colors'), 0.00011182503134379135)\n",
      "(('long', 'enough'), 0.00010776623541786501)\n",
      "(('high', 'quality'), 0.00010708976943021062)\n",
      "(('flip', 'flops'), 0.00010464408470561397)\n",
      "(('looks', 'good'), 0.00010152193399336294)\n",
      "(('second', 'pair'), 9.886810588794955e-05)\n",
      "(('size', 'smaller'), 9.444505904559392e-05)\n",
      "(('perfect', 'fit'), 9.173919509497634e-05)\n",
      "(('another', 'one'), 9.158308755936379e-05)\n",
      "(('really', 'cute'), 9.12188366429345e-05)\n",
      "(('buy', 'another'), 9.101069326211777e-05)\n",
      "(('first', 'pair'), 9.002201220323827e-05)\n",
      "(('fits', 'great'), 9.002201220323827e-05)\n",
      "(('many', 'compliments'), 8.89292594539504e-05)\n",
      "(('years', 'ago'), 8.840890100190856e-05)\n",
      "(('fit', 'perfect'), 8.747225578823326e-05)\n"
     ]
    }
   ],
   "source": [
    "finder.apply_word_filter(Alpha)\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "finder.apply_word_filter(lambda w: w in stopwordsUpper)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Badgley', 'Mischka'), 21.873990889369754)\n",
      "(('Krav', 'Maga'), 21.873990889369754)\n",
      "(('Pee', 'Wee'), 21.873990889369754)\n",
      "(('Salvatore', 'Exte'), 21.873990889369754)\n",
      "(('SpatesTruck', 'Lenders'), 21.873990889369754)\n",
      "(('Tessuto', 'Vela'), 21.873990889369754)\n",
      "(('WorkFlex', 'Ear-Flap'), 21.873990889369754)\n",
      "(('Birko', 'Flor'), 21.610956483535958)\n",
      "(('PARADISE', 'BORDER'), 21.610956483535958)\n",
      "(('Herman', 'Munster'), 21.38856406219951)\n",
      "(('Hola', 'Gente'), 21.38856406219951)\n",
      "(('Mossy', 'Oak'), 21.38856406219951)\n",
      "(('Myia', 'Passiello'), 21.38856406219951)\n",
      "(('Charmed', 'Memories'), 21.347922077702165)\n",
      "(('Saudi', 'Arabia'), 21.347922077702165)\n",
      "(('NEWPORT', 'BLVD'), 21.195918984257116)\n",
      "(('Grady', 'Harp'), 21.195918984257112)\n",
      "(('Norman', 'Reedus'), 21.195918984257112)\n",
      "(('Steam', 'Punk'), 21.195918984257112)\n",
      "(('Sherpani', 'Soleil'), 21.125529656365718)\n",
      "(('GEL-NOOSA', 'TRI-7'), 21.025993982814803)\n",
      "(('Chase', 'Von'), 20.973526562920664)\n",
      "(('Buzz', 'Lightyear'), 20.873990889369754)\n",
      "(('Muk', 'Luks'), 20.873990889369754)\n",
      "(('Bon', 'Bebe'), 20.87399088936975)\n",
      "(('Giorgio', 'Brutini'), 20.87399088936975)\n",
      "(('Johanna', 'T25'), 20.87399088936975)\n",
      "(('allen', 'edmonds'), 20.833348904872405)\n",
      "(('Handled', 'Shoehorn'), 20.78088148497827)\n",
      "(('INITIAL', 'IMPRESSION'), 20.78088148497827)\n",
      "(('Laurel', 'Burch'), 20.73648736561982)\n",
      "(('GON', 'NA'), 20.736487365619816)\n",
      "(('Rhonda', 'Shear'), 20.736487365619816)\n",
      "(('Self', 'Expressions'), 20.736487365619816)\n",
      "(('Zombie', 'Apocalypse'), 20.736487365619816)\n",
      "(('Blister', 'Resist'), 20.710492157086872)\n",
      "(('Daylight', 'Savings'), 20.651598468033303)\n",
      "(('Tractor', 'Supply'), 20.610956483535958)\n",
      "(('Uncle', 'Milty'), 20.610956483535958)\n",
      "(('buenas', 'tardes'), 20.610956483535958)\n",
      "(('Libby', 'Sue'), 20.58448427217477)\n",
      "(('Vince', 'Camuto'), 20.566562364177503)\n",
      "(('Carolyn', 'Pollack'), 20.517847079144477)\n",
      "(('Liz', 'Claiborne'), 20.514094944283368)\n",
      "(('fecha', 'indicada'), 20.514094944283368)\n",
      "(('Caslynn', 'Lizzie'), 20.511420809985044)\n",
      "(('WEB', 'PAGE.I'), 20.49547926611602)\n",
      "(('Angry', 'Birds'), 20.458953390090908)\n",
      "(('Friendly', 'Swede'), 20.414559270732454)\n",
      "(('CharmsFashion', 'Handmade'), 20.38856406219951)\n"
     ]
    }
   ],
   "source": [
    "finder2 = BigramCollocationFinder.from_words(token)\n",
    "finder2.apply_word_filter(Alpha)\n",
    "finder2.apply_word_filter(lambda w: w in stopwords)\n",
    "finder2.apply_word_filter(lambda w: w in stopwordsUpper)\n",
    "finder2.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
